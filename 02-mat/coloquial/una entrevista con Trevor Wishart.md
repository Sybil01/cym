---
tags:
  - músicaelectrónica
place:
person: Trevor Wishart
connections:
url: https://www.researchgate.net/publication/220386646_An_Interview_with_Trevor_Wishart
photo: https://i.imgur.com/g5qYUZA.png
topoi: música electrónica
year: 2008
---

El Proyecto U.S.O. tuvo el placer de entrevistar a Trevor Wishart, cuyo trabajo ha sido recientemente galardonado con el «Premio Giga-Hertz de música electrónica 2008». El «Gran Premio» reconoció sus logros artísticos y técnicos a lo largo de su carrera.
Trevor Wishart, nacido en 1946 en Leeds, es un compositor e intérprete que desarrolló (entre otras cosas) herramientas de transformación del sonido en su paquete de software Sound Loom - Composers’ Desktop Project. Es autor de los libros de renombre mundial «On Sonic Art» y «Audible Design», en los que comparte su amplia investigación sobre la voz humana ampliada y las técnicas de música por ordenador para la transformación del sonido. Actualmente es «Arts Council Composer Fellow» en el Departamento de Música de la Universidad de Durham, Inglaterra.


USO: Ha sido galardonado en el Festival de Bourges, en Ars Electronica y ahora en Giga-Hertz, tres prestigiosos premios de música electrónica. ¿Cómo se siente ahora ante todos estos homenajes a su trabajo como compositor?

TW: Es muy gratificante recibir este tipo de reconocimiento por parte de la comunidad musical, sobre todo porque el tipo de música que hago es casi invisible en la prensa cultural del Reino Unido, donde la composición electroacústica se ve desplazada entre la música instrumental clásica y la música popular.


USO: ¿Cómo empezó a interesarse por la composición musical?

TW: Me crié en una familia de clase trabajadora, sin ninguna conexión real con el mundo de los conciertos o los teatros, pero en casa había un piano, una reliquia familiar, que nadie tocaba nunca. Me fascinaba, así que mis padres accedieron a dejarme tomar clases de piano. Poco después, cuando tenía 7 años, estaba mirando el escaparate de la única tienda de música clásica de la ciudad y me fijé en un libro extraño, una partitura sin notas (era un libro de manuscritos). Inmediatamente compré uno y empecé a escribir mi propia música.


USO: ¿Por qué elegiste el medio electrónico y cómo ha influido esto en tu forma de componer?

TW: Fui a la universidad para estudiar Química (mis padres no podían imaginar la música como un trabajo real... mi colegio me desaconsejó seguir con este «diletantismo»), pero pronto me cambié a música. Después de que mi tutor de la universidad de Oxford me lanzara a la piscina en Darmstadt, estaba componiendo música instrumental compleja (7 series tonales con diferentes estructuras interválicas + tablas de números aleatorios) cuando murió mi padre. Él trabajaba en una fábrica en Leeds y, de repente, sentí que estaba desconectado de su mundo. Así que compré la única grabadora que podía permitirme (funcionaba a 3+3/4 pulgadas por segundo y tenía un micrófono incorporado de mala calidad) y recorrí fábricas y centrales eléctricas en Nottingham y Leeds, grabando los sonidos de la maquinaria industrial, con la vaga idea de componer una pieza para él. En el estudio descubrí que muchas de mis suposiciones sobre la composición se veían cuestionadas en este nuevo medio. Los sonidos tenían vida propia que había que respetar. Las nociones absolutas preconcebidas sobre las proporciones y las relaciones musicales se veían cuestionadas por la realidad concreta de los propios sonidos. Después de dos grandes proyectos iniciales («Machine» y «Journey-into-Space»), me decidí por una forma de trabajar con materiales complejos basada en la idea de la transformación del sonido, en la obra «Red Bird».

«Red Bird» trata los sonidos del mundo real (pájaros, animales, voces, máquinas) como metáforas en un paisaje mítico, en el que un tipo de sonido se transforma en otro para crear una forma a medio camino entre la música y la narrativa mítica. De hecho, el enfoque me lo sugirió la lectura de «El crudo y el cocido», de Lévi Strauss, donde utiliza la música como una especie de metáfora de su enfoque antropológico estructural del mito. Mi idea era darle la vuelta y crear un mito contemporáneo (sobre el industrialismo, el determinismo, la «libertad» y la creatividad) utilizando el sonido y la estructura musical. El enfoque de la transformación del sonido (muy difícil de lograr en un estudio analógico) se inspiró en parte en una idea política: la posibilidad de cambiar el mundo social.

Con la llegada de los ordenadores, el control muy preciso de la estructura del sonido hizo posible adoptar la transformación del sonido como enfoque general de los materiales musicales. Considero que se trata de una generalización de las ideas clásicas de variación y desarrollo, extendidas a todo el dominio espectral.

USO: Prefieres utilizar muestras generadas a partir de fuentes vocales interpretadas por ti mismo con técnicas extendidas. ¿Podrías describir el proceso de creación?

TW: No estrictamente. Utilizo muy a menudo la voz humana (a veces la mía propia, a veces la de intérpretes en directo como «Electric Phoenix» o «Singcircle», a veces voces de los medios de comunicación o de la comunidad local) por dos razones. Por un lado, la voz es mucho más que un instrumento musical. A través del habla, nos conecta con el mundo social y, por ende, con las tradiciones de la poesía, el teatro, la comedia, etc. Revela mucho sobre el hablante, desde su género, edad y salud hasta su actitud, estado de ánimo e intención, y también nos conecta con nuestros parientes primates. El oyente reconoce una voz incluso cuando está mínimamente indicada o muy transformada, del mismo modo que reconocemos los rostros a partir de muy pocas pistas. Y el oyente medio se verá afectado, por ejemplo, por un multifónico vocal, un vínculo empático o gutural inmediato, de una manera que no se verá afectado por un multifónico de clarinete (más apreciado en el ámbito de los aficionados a la música contemporánea).

Al mismo tiempo, aparte del propio ordenador, la voz es el «instrumento» más rico que tenemos para producir sonido, ya que genera una gran variedad de sonidos, desde los de tono estable hasta los totalmente ruidosos, pasando por multifónicos complejos que cambian rápidamente o texturas ásperas, etc. Se trata de una rica veta que explotar para la exploración musical.

Mi proceso de creación musical depende de la obra en cuestión. Normalmente tengo una idea general (una «poética») para la obra. Por ejemplo, «Imago» tiene la idea de acontecimientos sorprendentes que surgen de orígenes improbables (al igual que la fase imago de la metamorfosis de los insectos, la mariposa, emerge de la poco atractiva pupa). En el caso de «Globalalia», la idea es expresar la conexión entre los seres humanos explorando los elementos fundamentales de todas las lenguas, las sílabas. También tengo algunas nociones generales sobre cómo funcionan las formas musicales... Es importante para el oyente que se indiquen claramente los materiales principales en un contexto en el que no se utiliza un lenguaje musical tradicional; establecer momentos clave o clímax en la obra; la repetición y el desarrollo, y la recapitulación de los materiales, especialmente los que conducen hacia y se alejan de estos focos, etc. La repetición y la recapitulación (posiblemente transformada) son especialmente importantes para que el oyente pueda trazar un camino a través de una forma musical extendida.

Pero todos los materiales sonoros son diferentes y no es posible predecir, salvo en los casos más obvios, lo que surgirá cuando se empiece a transformar los sonidos. Por eso dedico mucho tiempo a explorar, jugar con las fuentes, transformarlas y transformar las transformaciones, y poco a poco se cristaliza en el estudio un esquema formal adecuado a lo que descubro y a esos materiales concretos.


USO: ¿Cómo fue tu experiencia trabajando en el IRCAM para «Vox 5»?

TW: Mi primera visita al IRCAM fue la experiencia de aprendizaje más emocionante de mi vida. Descubrir las posibilidades que abría el análisis y la transformación de los sonidos mediante software, aprender sobre psicoacústica en las inspiradoras conferencias de Steve McAdams y relacionarme con investigadores de gran prestigio rebosantes de nuevas ideas. Como probablemente sabéis, me ofrecieron la oportunidad de crear una pieza durante mi visita en 1981, pero entonces cambió todo el hardware del IRCAM y no fue hasta 1986 cuando pude empezar a trabajar en «VOX-5», una pieza que surgió de la experiencia de «Red Bird». Me asignaron un mentor (Thierry Lancino), pero pronto se dio cuenta de que probablemente podría arreglármelas por mi cuenta (mi formación científica en la escuela hacía que la programación me resultara natural), y pronto descubrí el Phase Vocoder, desmontando los archivos de datos para descubrir qué contenían y utilizando este conocimiento para empezar a diseñar herramientas de transformación de sonido basadas en la transformación de esos datos.

USO: Llevas varios años dedicado al desarrollo de software. ¿Por qué decidiste crear tus propias herramientas? ¿Puedes contarnos cómo surgió y cómo se desarrolló el proyecto Composer Desktop?

TW: Hay dos razones principales. La primera es la pobreza (!). La mayor parte de mi vida he sido compositor autónomo, ¡y ser compositor experimental autónomo en Inglaterra es realmente difícil! Cuando empecé a trabajar con electrónica, dependías de cajas negras hechas a medida, como la SPX90. El problema para mí era que, aunque pudiera permitirme comprar una, no podía permitirme actualizarla cada dos años, como hacían los departamentos de música de las universidades. Quedó claro que la solución a este problema sería disponer de un software similar al del IRCAM que se pudiera ejecutar en un ordenador de sobremesa. Un grupo de compositores e ingenieros con ideas afines de York se reunieron (en 1985-1986) para crear el Composers' Desktop Project y comenzaron a adaptar parte del software del IRCAM/Stanford al Atari ST (el MAC era entonces demasiado lento para el audio profesional). A continuación, comenzamos a diseñar nuestro propio software.

La segunda razón es que crear tus propios instrumentos te permite seguir tu imaginación sonora allá donde te lleve, en lugar de estar limitado por las restricciones del software comercial. Puedes desarrollar o ampliar un instrumento cuando lo consideres necesario (y no cuando el productor comercial decida que es rentable hacerlo), ¡y puedes arreglarlo si falla!

Las versiones originales para Atari funcionaban muy lentamente: por ejemplo, realizar una transformación espectral de un sonido estéreo de 4 segundos podía llevar 4 minutos en el IRCAM, pero 2 días en el Atari. Sin embargo, en tu propio sistema en casa, podías permitirte esperar... sin duda era más fácil que intentar acceder a las grandes instituciones cada vez que querías crear una pieza.

Poco a poco, los ordenadores se hicieron más rápidos, incluso el IRCAM pasó a utilizar MAC. El CDP pasó al PC (¡los MAC eran demasiado caros para los autónomos!) y el software se hizo gradualmente más rápido que el tiempo real.

El CDP siempre ha sido un sistema basado en la escucha, y durante mucho tiempo me resistí a crear cualquier interfaz gráfica, ya que gran parte del software comercial tenía una interfaz de aspecto glamuroso que ocultaba posibilidades musicales limitadas. Sin embargo, a mediados de los 90, acabé desarrollando el «Sound Loom» en TK/Tcl (este lenguaje fue especialmente útil, ya que permitía desarrollar la interfaz sin cambiar los programas de procesamiento de sonido subyacentes). Las ventajas de la interfaz pronto se hicieron evidentes, en particular su capacidad para almacenar un historial infinito de actividades musicales, guardar parches de parámetros y crear multiprocesos (denominados «Instrumentos»). Más recientemente, he añadido herramientas para gestionar grandes cantidades de archivos. El «procesamiento masivo» permite enviar cientos de archivos al mismo proceso, mientras que los «archivos de propiedades» permiten asignar propiedades y valores definidos por el usuario a los sonidos, que luego pueden seleccionarse en función de esas propiedades. Cada vez hay más funciones de alto nivel que combinan varios procesos CDP para lograr una funcionalidad superior.


USO: ¿Cómo desarrollaste tus habilidades en la programación de algoritmos para el dominio espectral?

TW: Estudié ciencias y matemáticas en el colegio y cursé un trimestre de matemáticas universitarias (para químicos). Las matemáticas siempre han sido una de mis aficiones, son hermosas, como la música. Cuando tenía 15 años, mi colegio organizó una visita al ordenador de la universidad local (Leeds), una bestia enorme y misteriosa escondida en una sala con aire acondicionado desde donde se alimentaba con lectores de tarjetas perforadas. Entonces escribí mis primeros programas en Algol. No empecé a programar hasta más tarde, cuando era estudiante en York, cuando Clive Sinclair sacó al mercado su primer ordenador doméstico ultrabarato. Aprendí Basic por mi cuenta, pasé a otras máquinas Sinclair, hasta llegar al último «QL», que utilicé para controlar la espacialización del sonido utilizada en VOX-1. Más tarde pasé a C.

Nunca he recibido clases formales de programación ni he hecho un curso propiamente dicho, pero he tenido la suerte de codearme con algunos genios de la programación, como Martin Atkins, que diseñó el sistema de sonido del CDP, y Miller Puckette, del IRCAM, de quien aprendí algunos consejos útiles... ¡pero sigo siendo solo un aficionado con talento en lo que se refiere a la programación!

USO: ¿Podría explicarnos su preferencia por el software de procesamiento offline en lugar de los entornos en tiempo real?

TW: El trabajo offline y en tiempo real son diferentes tanto desde el punto de vista de la programación como desde el punto de vista musical. Lo principal con lo que no hay que lidiar en el trabajo offline es con la necesidad de realizar el procesamiento en un tiempo específico. El programa debe ser eficiente y rápido, y comprender las cuestiones de sincronización. En el trabajo offline, todo esto es simplemente irrelevante. Además, fuera de línea, puedes tomarte tu tiempo para producir un resultado sonoro; por ejemplo, un proceso puede consultar todo el sonido y tomar algunas decisiones sobre qué hacer, ejecutar un segundo proceso y, sobre la base de este, ejecutar un tercero, y así sucesivamente. A medida que las máquinas se vuelven más rápidas y los programadores más inteligentes (y si los compositores están contentos con que los sonidos se procesen offline y se vuelvan a inyectar en el sistema más tarde), probablemente se puedan sortear la mayoría de estos problemas.

Pero la principal diferencia es estética. Si se procesa un evento en directo, hay que aceptar todo lo que entra por el micrófono o el dispositivo de entrada. Por muy precisa que sea la partitura, los sonidos que entran siempre serán sutilmente diferentes en cada actuación. Por lo tanto, los procesos que se utilicen deben funcionar con una gama de entradas potenciales.
El principal problema de la música en directo es que hay que ser el tipo de persona a la que le gusta ir a conciertos o que se siente cómoda en el ambiente social de los conciertos. Y mucha gente no lo es. Esto se puede cambiar, por un lado, mediante la educación, pero, lo que es más importante, haciendo que el mundo de los conciertos sea más accesible a más grupos de personas y, por ejemplo, llevando las actuaciones a lugares poco habituales (yo he actuado en clubes de trabajadores, escuelas, etc.).

Al trabajar fuera de línea, se puede trabajar con las características únicas de un sonido concreto, ya sea un multifónico que se ha conseguido generar en una sesión de improvisación, pero que no es simplemente «reproducible» a voluntad, o la grabación de un evento transitorio o de un individuo específico, que no se puede reproducir a voluntad en una actuación. Además, la ausencia de intérpretes en el escenario puede parecer una debilidad, pero tiene sus propias recompensas. Comparemos el teatro y el cine. Una actuación en directo tiene ventajas evidentes: el contacto con músicos vivos, el teatro del escenario, etc., pero uno siempre está definitivamente allí, en la sala de conciertos. En el evento electroacústico puro podemos crear un mundo onírico que puede ser realista, abstracto, surrealista o todas estas cosas en diferentes momentos: un teatro para los oídos en el que podemos transportarnos lejos del aquí y ahora a un mundo de sueños. La música electroacústica no es diferente del cine en lo que respecta a su repetibilidad, excepto que la difusión del sonido, en manos de un difusor experto, puede hacer que cada actuación sea única, una interacción con el público, la situación del concierto y la acústica del espacio. Separar la música de la inmediatez del escenario de un concierto nos permite explorar mundos imaginarios, conjurados en el sonido, más allá de las convenciones sociales de la sala de conciertos.

USO: ¿Qué opinas sobre el tema de la espacialización?

TW: En los años 70 trabajaba con un equipo analógico de 4 pistas. Pero luego la tecnología de 4 pistas desapareció. Desde entonces he sido cauteloso a la hora de utilizar cualquier procedimiento de espacialización más allá del estéreo, ya que no quiero que mi trabajo dependa de una tecnología que podría no durar. También me preocupa el oyente medio, que no va a ir a un concierto ni a una institución especial con complejas instalaciones de espacialización. La mayoría de la gente escucha música con auriculares o equipos de alta fidelidad domésticos. Por lo tanto, la música debe funcionar en este contexto. Sin embargo, con la difusión puedo ampliar el trabajo estéreo, utilizando el proceso de difusión para reforzar y ampliar los gestos dentro de la música. Mi pieza actual probablemente será en 8 pistas, en parte por razones estéticas, ya que se basa en el habla humana reconocible y me gustaría que la «comunidad» del habla rodease al público, y en parte porque el 8 pistas es, quizás, a prueba de futuro, ¡ya que es esencialmente 4 veces estéreo! Me entusiasman los sistemas de espacialización multicanal que se están desarrollando en este momento, pero me gustaría ver el desarrollo de altavoces muy baratos y de alta calidad, para que estas tecnologías sean accesibles a salas más pequeñas (normales) y a compositores como yo, que trabajamos en casa.


USO: ¿Cómo debe interpretarse tu música (por ti o por cualquier otro artista sonoro) en un contexto en directo?

TW: En el caso de las obras puramente electroacústicas, las piezas (estéreo) deben difundirse a través de muchos pares estéreo. Yo proporciono partituras de difusión básicas si no soy yo quien difunde las piezas.


USO: ¿Qué opinas del enfoque estructural en la composición musical? ¿Crees que podría ser útil crear herramientas para la composición asistida por ordenador con el fin de agilizar el trabajo del compositor?

TW: Es absolutamente esencial, no hay música sin estructura. Pero la composición asistida por ordenador es algo para la música comercial y el cine, donde no queremos desviarnos de los caminos conocidos, por lo que nos complace encapsularlos en un algoritmo. En cuanto a la música artística, quiero escuchar cómo otra persona da forma a los materiales para ofrecerme una experiencia musical. No me interesa escuchar el resultado de un algoritmo, aunque, por supuesto, los algoritmos pueden utilizarse a pequeña escala para ayudar a dar forma a eventos concretos.


USO: ¿Tu carrera académica te ha ayudado a ampliar tus conocimientos sobre tu forma de componer?

TW: Sí. Como estudiaba Química en Oxford, cuando cambié de asignatura a Música, fue a uno de los departamentos de música más conservadores del Reino Unido, pero me alegro de haber entrado en contacto con la música desde la Edad Media hasta principios del siglo XX y de haber aprendido los diferentes enfoques que los compositores han adoptado para organizar sus materiales a lo largo de cientos de años.


USO: ¿Hay en tu música alguna referencia técnica o inspiradora a compositores del pasado?

TW: No lo creo. O, mejor dicho, todavía no.


USO: ¿Cuáles son tus proyectos para el futuro próximo?

TW: Mi proyecto actual, una residencia de tres años, consiste en grabar las voces de muchas personas de la comunidad del noreste de Inglaterra. He grabado en colegios, centros de mayores, pubs y hogares. Quiero capturar a la gente hablando con naturalidad y recopilar una amplia gama de tipos de voces: diferentes edades, desde los 4 hasta los 93 años, géneros y cualidades vocales. Mi intención es crear una pieza electroacústica de aproximadamente una hora, en cuatro «actos», que juegue tanto con la singularidad de cada hablante como con las características comunes de la voz que todos compartimos. La pieza debe ser comprensible para la comunidad local, en particular para las personas cuyas voces he grabado (¡pocas de las cuales tienen un interés especial en la música experimental!), pero también para un público internacional, en el que no puedo dar por sentado que los oyentes entiendan el inglés.


```ref
Vassilandonakis, Y. (2009). An interview with Trevor Wishart. Computer Music Journal, 33, 8–23. https://doi.org/10.1162/comj.2009.33.2.8
```
